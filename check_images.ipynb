{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:57:00.000412Z",
     "start_time": "2024-05-28T15:56:59.997171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# image_folder = \"./LongDiseaseDatasetCovidNormalTuberculosis\"\n",
    "train_dir ='./images/train'\n",
    "validation_dir = './images/val'\n",
    "test_dir = './images/test'"
   ],
   "id": "9439c68a0edea6d3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:39:48.803203Z",
     "start_time": "2024-05-28T21:39:48.640935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "import numpy as np\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = image_dataset_from_directory(train_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)"
   ],
   "id": "16005a3fdda90f2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3645 files belonging to 3 classes.\n",
      "Found 1214 files belonging to 3 classes.\n",
      "Found 1219 files belonging to 3 classes.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T16:16:11.019609Z",
     "start_time": "2024-05-28T16:16:02.947900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def image_metadata(dataset):\n",
    "    three_channels = 0\n",
    "    two_channels = 0\n",
    "    try:\n",
    "        for batch in dataset:\n",
    "            images, labels = batch\n",
    "            for img in images:\n",
    "                shape = img.shape\n",
    "                if len(shape) == 3:\n",
    "                    channels = shape[2]\n",
    "                    if channels == 3:\n",
    "                        three_channels = three_channels + 1\n",
    "                    if channels < 2:\n",
    "                        two_channels = two_channels + 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(f\"Reached the end of the {dataset_name} dataset.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    return three_channels, two_channels\n",
    "                \n",
    "\n",
    "train_dataset_metadata =  image_metadata(train_dataset)\n",
    "validation_dataset_metadata = image_metadata(validation_dataset)\n",
    "test_dataset_metadata = image_metadata(test_dataset)\n",
    "\n",
    "print(\"3 canales, otro\")\n",
    "print(train_dataset_metadata)\n",
    "print(validation_dataset_metadata)\n",
    "print(test_dataset_metadata)"
   ],
   "id": "c114a7d7d578981b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 17:16:07.930558: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-28 17:16:09.471044: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 canales, otro\n",
      "(3645, 0)\n",
      "(1214, 0)\n",
      "(1219, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 17:16:11.017959: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:44:08.412290Z",
     "start_time": "2024-05-28T21:43:59.020597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "def categorize_images(dataset, dataset_name):\n",
    "    high_value_images = []\n",
    "    low_value_images = []\n",
    "    \n",
    "    print(f\"Categorizing images from {dataset_name}:\")\n",
    "    for batch in dataset:\n",
    "        images, labels = batch\n",
    "        for img in images:\n",
    "            \n",
    "            # Define threshold to consider high values\n",
    "            threshold = 75\n",
    "            \n",
    "             # Check if all channels have high values\n",
    "            if tf.reduce_all(img > threshold):\n",
    "                high_value_images.append(img)\n",
    "            else:\n",
    "                low_value_images.append(img)\n",
    "    \n",
    "    print(f\"{dataset_name} - High value images: {len(high_value_images)}, Low value images: {len(low_value_images)}\")\n",
    "    return high_value_images, low_value_images\n",
    "\n",
    "# Categorize images in each dataset\n",
    "train_high, train_low = categorize_images(train_dataset, \"Train Dataset\")\n",
    "validation_high, validation_low = categorize_images(validation_dataset, \"Validation Dataset\")\n",
    "test_high, test_low = categorize_images(test_dataset, \"Test Dataset\")\n",
    "\n",
    "# Example: Processing grouped images\n",
    "# You can now process or analyze the grouped images as needed\n",
    "print(f\"Total high value images in Train Dataset: {len(train_high)}\")\n",
    "print(f\"Total low value images in Train Dataset: {len(train_low)}\")"
   ],
   "id": "a497f1f51b039e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing images from Train Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 22:44:04.572143: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset - High value images: 7, Low value images: 3638\n",
      "Categorizing images from Validation Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 22:44:06.479017: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dataset - High value images: 5, Low value images: 1209\n",
      "Categorizing images from Test Dataset:\n",
      "Test Dataset - High value images: 1, Low value images: 1218\n",
      "Total high value images in Train Dataset: 7\n",
      "Total low value images in Train Dataset: 3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 22:44:08.409330: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
